from fastapi import FastAPI, HTTPException, BackgroundTasks, Security, Depends
from fastapi.security import APIKeyHeader
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import pandas as pd
import os
import logging
from datetime import datetime
from typing import Optional
import httpx

from .database_updater import DatabaseUpdater

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Force logging to flush immediately to prevent buffering issues
logging.getLogger().setLevel(logging.INFO)
for handler in logging.getLogger().handlers:
    handler.flush()
    if hasattr(handler, 'stream'):
        handler.stream.flush()

app = FastAPI(
    title="Malware Database API",
    description="API to check if hash values are associated with malware",
    version="1.0.0"
)

# API Key Security
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=True)

# Global variables
malware_db = None
db_updater = None
DB_FILE = "/app/data/malware_database.csv"
API_KEY = os.getenv("API_KEY", "your-secret-api-key-here")
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://ollama:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2:3b")
try:
    OLLAMA_MAX_TOKENS = int(os.getenv("OLLAMA_MAX_TOKENS", "350"))
except ValueError:
    OLLAMA_MAX_TOKENS = 350

# Compare header value with the API key loaded from environment
async def get_api_key(api_key: str = Security(api_key_header)):
    """Validate API key"""
    logger.debug(f"API Key validation: received={api_key[:10]}..., expected={API_KEY[:10]}...")
    if api_key != API_KEY:
        logger.warning(f"API Key validation FAILED: received key does not match")
        raise HTTPException(
            status_code=401,
            detail="Invalid or missing API Key"
        )
    logger.debug("API Key validation: SUCCESS")
    return api_key


class HashQuery(BaseModel):
    hash: str
    hash_type: Optional[str] = None  # sha256, md5, or sha1
    agent_name: Optional[str] = None  # Wazuh agent name
    path: Optional[str] = None  # File path
    username: Optional[str] = None  # Username who created/modified file
    timestamp: Optional[str] = None  # Timestamp when file was detected


class MalwareInfo(BaseModel):
    is_malware: bool
    hash: str
    hash_type: str
    details: Optional[dict] = None
    title: Optional[str] = None
    explanation: Optional[str] = None
    agent_name: Optional[str] = None
    path: Optional[str] = None
    username: Optional[str] = None
    timestamp: Optional[str] = None

# Build a short, structured context block for the LLM prompt 
async def generate_explanation(malware_entry: dict, hash_type: str, hash_value: str, agent_name: str = None, path: str = None, username: str = None, timestamp: str = None) -> Optional[dict]:
    """Generate a non-technical explanation using the Ollama LLM service."""
    summary_lines = [
        "Malware hash lookup result:",
        f"Hash ({hash_type}): {hash_value}",
        f"First seen (UTC): {malware_entry.get('first_seen_utc')}",
        f"File name: {malware_entry.get('file_name')}",
        f"File type: {malware_entry.get('file_type_guess')}",
        f"MIME type: {malware_entry.get('mime_type')}",
        f"Signature: {malware_entry.get('signature')}",
        f"Reporter: {malware_entry.get('reporter')}",
        f"VirusTotal detection rate: {malware_entry.get('vtpercent')}",
    ]
    
    # Add context information if available
    if agent_name:
        summary_lines.append(f"Detected on agent: {agent_name}")
    if path:
        summary_lines.append(f"File path: {path}")
    if username:
        summary_lines.append(f"User: {username}")
    if timestamp:
        summary_lines.append(f"Detection time: {timestamp}")
    
    user_prompt = "\n".join(summary_lines)

     # Prepare Ollama chat payload
    payload = {
        "model": OLLAMA_MODEL,
        "stream": False,
        "options": {"num_predict": OLLAMA_MAX_TOKENS, "temperature": 0},
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are a security analyst. Explain malware findings in simple, calm language for non-technical users. "
                    "Include context details (agent, user, path, time) when provided in your explanation. "
                    "Respond ONLY with a valid JSON object containing 'title' (max 30 chars, short title with the type of malware) and 'explanation' "
                    "(max 200 chars, explanation the type of malware with context and brief remediation). "
                    "Escape backslashes in any file paths (use double backslashes) so the JSON stays valid. "
                    "REQUIRED FORMAT: {\"title\": \"[specific threat type]\", \"explanation\": \"[explanation with context and remediation]\"}. "
                    "Example: {\"title\": \"Trojan stealer\", \"explanation\": \"Detected on agent 'server1' by user 'john' at /home/bob/file.exe at '12:00'. This malware steals data. Remove immediately and scan your system.\"}"
                ),
            },
            {"role": "user", "content": user_prompt},
        ],
    }

    # Call Ollama chat endpoint and return parsed JSON result 
    async def _chat(client: httpx.AsyncClient) -> Optional[dict]:
        logger.debug(f"Making LLM request with payload - model={OLLAMA_MODEL}, max_tokens={OLLAMA_MAX_TOKENS}")
        response = await client.post(f"{OLLAMA_URL.rstrip('/')}/api/chat", json=payload)
        response.raise_for_status()
        data = response.json()
        logger.debug(f"LLM response received - response keys: {data.keys()}")
        message = data.get("message", {}).get("content")
        logger.debug(f"LLM message content length: {len(message) if message else 0}")
        if message:
            logger.debug(f"LLM raw message: {message[:500]}")  # Log first 500 chars
            try:
                import json
                # Try to extract JSON from the response
                content = message.strip()
                # Find JSON object in response
                start = content.find('{')
                end = content.rfind('}') + 1
                logger.debug(f"JSON extraction - start={start}, end={end}, total_length={len(content)}")
                if start >= 0 and end > start:
                    json_str = content[start:end]
                    logger.debug(f"Extracted JSON string: {json_str[:350]}")
                    result = json.loads(json_str)
                    logger.debug(f"Parsed JSON - keys: {result.keys()}")
                    if "title" in result and "explanation" in result:
                        logger.debug(f"SUCCESS: Extracted title='{result['title']}', explanation='{result['explanation'][:100]}...'")
                        # Enforce character limits
                        return {
                            "title": result["title"][:80],
                            "explanation": result["explanation"][:350]
                        }
                    else:
                        logger.warning(f"MISSING KEYS: result has keys {result.keys()}, expected 'title' and 'explanation'")
                else:
                    logger.warning(f"NO JSON FOUND in message (start={start}, end={end})")
            except json.JSONDecodeError as je:

                # Attempt recovery when backslashes in paths break JSON parsing
                logger.warning(f"JSON parse error: {je} in content: {message[:350]}")
                if 'json_str' in locals():
                    try:
                        safe_json = json_str.replace("\\", "\\\\")
                        result = json.loads(safe_json)
                        if "title" in result and "explanation" in result:
                            logger.warning("Recovered LLM JSON after escaping backslashes")
                            return {
                                "title": result["title"][:80],
                                "explanation": result["explanation"][:350]
                            }
                    except Exception:
                        pass
            except Exception as e:
                logger.warning(f"Error processing LLM response: {e}")
        else:
            logger.warning("LLM message content is empty or missing")
        return None

    async with httpx.AsyncClient(timeout=20.0) as client:
        try:
            result = await _chat(client)
            if result:
                return result
        except httpx.HTTPStatusError as exc:
            if exc.response.status_code == 404:
                # Likely model not present yet; pull once and retry.
                try:
                    logger.debug("Pulling Ollama model %s", OLLAMA_MODEL)
                    await client.post(
                        f"{OLLAMA_URL.rstrip('/')}/api/pull",
                        json={"name": OLLAMA_MODEL},
                        timeout=350.0,
                    )
                    result = await _chat(client)
                    if result:
                        return result
                except Exception as pull_exc:  # noqa: BLE001
                    logger.warning("LLM pull/retry failed: %s", pull_exc)
            logger.warning("LLM enrichment failed: %s", exc)
        except Exception as exc:  # noqa: BLE001
            logger.warning("LLM enrichment failed: %s", exc)
    return None


# load database
def load_database():
    """Load the malware database into memory"""
    global malware_db
    
    # Avoid crashing if the database file hasn't been downloaded yet
    if not os.path.exists(DB_FILE):
        logger.warning(f"Database file not found at {DB_FILE}")
        malware_db = None
        return
    
    try:
        # Define column names manually as the header line starts with "# "
        column_names = [
            "first_seen_utc", "sha256_hash", "md5_hash", "sha1_hash",
            "reporter", "file_name", "file_type_guess", "mime_type",
            "signature", "clamav", "vtpercent", "imphash", "ssdeep", "tlsh"
        ]
        
        # Read CSV, skipping the first 9 lines (comments + header with #)
        malware_db = pd.read_csv(
            DB_FILE,
            skiprows=9,
            names=column_names,
            skipinitialspace=True
        )
        logger.debug(f"Loaded {len(malware_db)} malware entries")
        logger.debug(f"Available columns: {list(malware_db.columns)}")
    except Exception as e:
        logger.error(f"Error loading database: {e}")
        malware_db = None


async def pull_ollama_model():
    """Pull the Ollama model on startup"""
    try:

        # Pre-pull the model so the first request does not block on download
        logger.debug(f"Pulling Ollama model {OLLAMA_MODEL}...")
        async with httpx.AsyncClient(timeout=300.0) as client:
            response = await client.post(
                f"{OLLAMA_URL.rstrip('/')}/api/pull",
                json={"name": OLLAMA_MODEL}
            )
            response.raise_for_status()
            logger.debug(f"Successfully pulled Ollama model {OLLAMA_MODEL}")
            return True
    except Exception as e:

        # Continue startup even if model pull fails (it will retry on first use)
        logger.warning(f"Failed to pull Ollama model: {e}")
        logger.warning("Model will be pulled on first use")
        return False


@app.on_event("startup")
async def startup_event():
    """Initialize the application on startup"""
    global db_updater
    
    logger.info("Starting Malware Database API")
    
    # Initialize database updater
    db_updater = DatabaseUpdater(DB_FILE)
    
    # Check if database exists, if not download it
    if not os.path.exists(DB_FILE):
        logger.info("Database not found, downloading initial database...")
        await db_updater.download_and_update()
    else:
        # Check if database is older than 24 hours
        db_age_hours = (datetime.now().timestamp() - os.path.getmtime(DB_FILE)) / 3600
        if db_age_hours > 24:
            logger.info(f"Database is {db_age_hours:.1f} hours old, updating...")
            await db_updater.download_and_update()
        else:
            logger.info(f"Database is {db_age_hours:.1f} hours old, no update needed")
    
    # Load database into memory
    load_database()
    
    # Pull Ollama model
    await pull_ollama_model()
    
    # Start scheduled updates (daily at 03:00)
    db_updater.start_scheduler(reload_callback=load_database)
    logger.info("Database updater scheduler started")


@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    if db_updater:
        # Stop scheduler to avoid background threads on shutdown
        db_updater.stop_scheduler()
    logger.info("Malware Database API shutdown complete")


@app.get("/")
async def root():
    """Root endpoint with API information"""
    db_status = "loaded" if malware_db is not None else "not loaded"
    db_count = len(malware_db) if malware_db is not None else 0
    
    return {
        "message": "Malware Database API",
        "version": "1.0.0",
        "database_status": db_status,
        "malware_entries": db_count,
        "endpoints": {
            "check_hash": "/check/{hash}",
            "check_hash_post": "/check",
            "database_info": "/info",
            "update_database": "/update"
        }
    }


@app.get("/info")
async def database_info(api_key: str = Depends(get_api_key)):
    """Get information about the database"""
    if malware_db is None:
        raise HTTPException(status_code=503, detail="Database not loaded")
    
    # Get last modified time of database file
    last_updated = None
    if os.path.exists(DB_FILE):
        last_updated = datetime.fromtimestamp(
            os.path.getmtime(DB_FILE)
        ).isoformat()
    
    return {
        "total_entries": len(malware_db),
        "last_updated": last_updated,
        "database_file": DB_FILE,
        "columns": list(malware_db.columns)
    }


@app.get("/check/{hash_value}")
async def check_hash_get(hash_value: str, api_key: str = Depends(get_api_key)):
    """Check if a hash is malware (GET request)"""
    # Wrap URL path value into the same flow used by POST requests 
    return await check_hash(HashQuery(hash=hash_value))


@app.post("/check")
async def check_hash_post(query: HashQuery, api_key: str = Depends(get_api_key)):
    """Check if a hash is malware (POST request)"""
    logger.info(f"POST /check endpoint called - hash={query.hash[:16]}...")
    result = await check_hash(query)
    logger.info(f"POST /check returning result: is_malware={result.is_malware}, has_title={result.title is not None}")
    return result


async def check_hash(query: HashQuery) -> MalwareInfo:
    """Check if a hash value is in the malware database"""
    logger.debug(f"check_hash called: hash={query.hash[:16]}..., agent={query.agent_name}, path={query.path}")
    
    if malware_db is None:
        logger.error("Database not loaded!")
        raise HTTPException(status_code=503, detail="Database not loaded")
    
    hash_value = query.hash.lower().strip()
    
    # Determine hash type if not specified
    hash_type = query.hash_type
    if not hash_type:
        hash_length = len(hash_value)
        if hash_length == 32:
            hash_type = "md5"
        elif hash_length == 40:
            hash_type = "sha1"
        elif hash_length == 64:
            hash_type = "sha256"
        else:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid hash length: {hash_length}. Expected 32 (MD5), 40 (SHA1), or 64 (SHA256)"
            )
    
    # Map hash type to column name
    hash_column_map = {
        "md5": "md5_hash",
        "sha1": "sha1_hash",
        "sha256": "sha256_hash"
    }
    
    if hash_type not in hash_column_map:
        raise HTTPException(
            status_code=400,
            detail=f"Invalid hash type: {hash_type}. Must be md5, sha1, or sha256"
        )
    
    column_name = hash_column_map[hash_type]
    logger.debug(f"Searching database using column: {column_name}")
    
    # Search for hash in database
    result = malware_db[malware_db[column_name].str.lower() == hash_value]
    
    if len(result) == 0:
        logger.debug(f"Hash NOT found in database: {hash_value}")
        # Generate title and explanation for clean file
        title = "No malware detected"
        explanation = f"No malware detected on {query.agent_name or 'this system'}"
        
        return MalwareInfo(
            is_malware=False,
            hash=hash_value,
            hash_type=hash_type,
            details=None,
            title=title,
            explanation=explanation,
            agent_name=query.agent_name,
            path=query.path,
            username=query.username,
            timestamp=query.timestamp
        )
    
    # Found malware - return details
    logger.debug(f"Hash FOUND in database - calling LLM for explanation")
    malware_entry = result.iloc[0].to_dict()

    # Enrich response with a short, user-friendly explanation from the LLM
    llm_result = await generate_explanation(
        malware_entry, 
        hash_type, 
        hash_value,
        agent_name=query.agent_name,
        path=query.path,
        username=query.username,
        timestamp=query.timestamp
    )
    
    logger.debug(f"LLM explanation generated: has_title={llm_result is not None and 'title' in llm_result}, {malware_entry.get('signature')}")
    
    return MalwareInfo(
        is_malware=True,
        hash=hash_value,
        hash_type=hash_type,
        details={
            "first_seen": malware_entry.get("first_seen_utc"),
            "sha256": malware_entry.get("sha256_hash"),
            "md5": malware_entry.get("md5_hash"),
            "sha1": malware_entry.get("sha1_hash"),
            "file_name": malware_entry.get("file_name"),
            "file_type": malware_entry.get("file_type_guess"),
            "mime_type": malware_entry.get("mime_type"),
            "signature": malware_entry.get("signature"),
            "reporter": malware_entry.get("reporter")
        },
        title=llm_result.get("title") if llm_result else None,
        explanation=llm_result.get("explanation") if llm_result else None,
        agent_name=query.agent_name,
        path=query.path,
        username=query.username,
        timestamp=query.timestamp
    )


@app.post("/update")
async def trigger_update(background_tasks: BackgroundTasks, api_key: str = Depends(get_api_key)):
    """Manually trigger a database update"""
    if db_updater is None:
        raise HTTPException(status_code=503, detail="Database updater not initialized")
    
    # Run update in the background so the API remains responsive
    background_tasks.add_task(db_updater.download_and_update)
    # Reload in-memory DataFrame after update finishes
    background_tasks.add_task(load_database)
    
    return {
        "message": "Database update triggered",
        "status": "running"
    }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    # Report healthy only when the database is loaded into memory
    is_healthy = malware_db is not None
    status_code = 200 if is_healthy else 503
    
    return JSONResponse(
        status_code=status_code,
        content={
            "status": "healthy" if is_healthy else "unhealthy",
            "database_loaded": is_healthy
        }
    )
